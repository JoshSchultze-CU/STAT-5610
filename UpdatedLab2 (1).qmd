---
title: "Lab2"
author: "Mountain Dewds"
format: pdf
editor: visual
date: 2025-02-24
---

## Lab2: Comparing Nonlinear Regressions

**Due: 11:59PM Sunday, March 2 on Canvas as a knitted pdf file of your team's Quarto document**

1.  You will individually fit **six** nonlinear regression models on a single X variable from your team's chosen dataset. You will use CV (including the built-in LOOCV functions in R) on at least three of these models to determine the best tuning parameters (e.g., $\lambda$ , K number of knots or steps, or degrees of freedom). You will compare the six models, choose the best one, make a prediction at an important value of X, interpret the results, and comment on the ethics of the situation.
2.  Teams will use the individual contributions to build a Generalized Additive Model (GAM), fit it, make predictions, make interpretations, show visualizations, etc.
3.  Each individual will comment on how they contributed to their team's GAM.

### Instructions for Lab2

In HW2, you applied several types of shrinkage and selection methods for linear models (shrinkage and selection methods) on a dataset of your choosing. This lab will be similar, but you will apply the nonlinear regression methods of Chapter 7 in *ISLR2* and use cross validation to choose the tuning parameters and select the best method. Individuals will model individual variables from the same dataset (one variable for each team member) and then combine their work into one team GAM that uses multiple X variables to predict Y.

#### What teams need to do first

1.  Choose a dataset that has enough interesting X variables that you can combine to model/predict Y. You can use one of the datasets that a teammate used for HW2 or pick a new one. You cannot use the Wage data from *ISLR2*.
2.  Decide who will model which X variable individually and when they need to be done to contribute to the team GAM.

#### What individuals need to do

1.  Given your team's dataset and your X variable, fit a polynomial regression, step function regression, cubic spline, natural spline, smoothing spline, and a local regression (six models).
2.  Use CV to determine the optimal tuning parameters for at least three of your models. Sometimes just choosing the tuning parameter (e.g., picking the number of cuts in X for a step function regression) based on your knowledge of Q1 and Q3 makes more sense than using CV.
3.  Compare the CV MSE or other appropriate model summary (e.g., misclassification rate) for your models. Choose the best model method.
4.  At an important or significant value of X (explain why that value of x0 is important or significant), use your model to predict Y at that value.
5.  Interpret your prediction and generally what the model is telling you about Y.
6.  Comment on any ethical implications of this work.
7.  Optional: Create visualizations of your models or just of the best model.

## JOSH INDIVIDUAL:

```{r}
install.packages("splines")
install.packages("dplyr")

```

1.  Our team data set is the Auto data set and my X variable is displacement. Below is some practice code for later portions of the lab:

    ```{r}
    ##Loading the dataset
    library(ISLR2)
    df <- data.frame(Auto)

    displacement_values<-data.frame("displacement"=df$displacement)


    ##Polynomial Regression

    poly_degree=4

    polyfit<- lm(data=df, mpg~ poly(displacement,poly_degree))

    poly_pred<-predict(polyfit,newdata=displacement_values)




    ##Step Function Regression
    cuts=4
    table(cut(df$displacement,cuts))
    stepfunctionfit<-lm(data=df, mpg~cut(displacement,cuts))

    step_pred<-predict(stepfunctionfit,newdata=displacement_values)



    ##Cubic Spline
    library(splines)
    knot_number=4
    knot_points=cut(df$displacement,knot_number)
    cubic_spline<-lm(data=df,mpg~bs(displacement, knots=knot_points))
    cubic_pred<-predict(cubic_spline,newdata=displacement_values)

    ##Natural Spline
    degrees_of_freedom=5
    natural_spline<-lm(data=df,mpg~ns(displacement, df=degrees_of_freedom,))
    natural_pred<-predict(natural_spline,newdata=displacement_values)

    ##Smoothing Spline

    duplicates<-duplicated(df$displacement)
    no_duplicated_df<-df[!duplicated(df[c('displacement')]), ]

    s_spline<-smooth.spline(no_duplicated_df$displacement,no_duplicated_df$mpg,cv=TRUE)
    no_dup_dis<-data.frame("displacement"=no_duplicated_df$displacement)
    smooth_pred<-predict(s_spline, newdata=no_dup_dis)

    #CV cross-validated df is
    print(s_spline$df)


    ##Local Regression
    span_val=0.4
    local_regression_fit<-loess(mpg~displacement,data=df, span=span_val)
    local_pred<-predict(local_regression_fit,newdata=displacement_values)

    ##Plot of fits
    library(ggplot2)

    ggplotstuff<-data.frame("mpg"=df$mpg,"displacement"=df$displacement,"poly"=poly_pred,"step"=step_pred,"cubic"=cubic_pred,"natural"=natural_pred,"local"=local_pred)

    ggplot(ggplotstuff,aes(y=mpg,x=displacement))+
      geom_point(color='black')+
      geom_line(aes(y=poly,x=displacement),color='blue')+
      geom_line(aes(y=step,x=displacement),color='red')+
      geom_line(aes(y=cubic,x=displacement),color='cyan')+
      geom_line(aes(y=natural,x=displacement),color='yellow')+
      geom_line(aes(y=local,x=displacement),color='pink')

    #seperate plot for smooth because it has trouble with duplicates

    duplicates<-duplicated(df$displacement)
    no_duplicated_df<-df[!duplicated(df[c('displacement')]), ]
    plot_stuff<-data.frame("mpg"=no_duplicated_df$mpg,"displacement"=no_duplicated_df$displacement,"smooth"=smooth_pred$y)

    ggplot(plot_stuff,aes(y=mpg,x=displacement))+geom_point(color='black')+
             geom_line(aes(y=smooth,x=displacement),color='orange')
    ```

2.  Using this code, I performed cross validation to find the optimal knot values. I had trouble finding all of the functions that would do cross validation for each of these, so I coded it directly. I coded 8-fold cross validation in this case and chose to minimize MSE (8 is a divisor of 392). In this case, I tried to optimize the polynomial regression, local regression and cubic spline. The natural spline had a build in CV function.

```{r}
set.seed(42)
k=8
n=392
width=n/k
test_indexes<-sample(1:392,replace=FALSE,n)
#initializing MSEs over each fold

poly_mse<-matrix(ncol=5,nrow=8,0)

local_mse<-matrix(ncol=20,nrow=8,0)

cubic_mse<-matrix(ncol=30,nrow=8,0)

for (i in 1:k){


test<-data.frame("mpg"=df[(test_indexes[as.integer(width*(i-1) ):as.integer(width*i)]),1],"displacement"=df[test_indexes[as.integer(width*(i-1) ):as.integer(width*i)],3])
test_displacement<-data.frame("displacement"=test$displacement)
train_index<-setdiff(test_indexes,test_indexes[as.integer(width*(i-1) ):as.integer(width*i)])
train<-data.frame("mpg"=df[train_index,1],"displacement"=df[train_index,3])


#Calculating MSE for possible values

#poly up to degree 5
for (j in 1:5){
poly_degree=j
polyfit<- lm(data=train, mpg~ poly(displacement,poly_degree))

poly_pred<-predict(polyfit,newdata=test_displacement)
poly_mse[i,j]<-mean((test$mpg-poly_pred)^2)
}

#span up from 0.1 (reasonable low value) to 0.2 (begins to overfit)
for (j in 10:20){
span_val=0.01*j
local_regression_fit<-loess(mpg~displacement,data=train, span=span_val)
local_pred<-predict(local_regression_fit,newdata=displacement_values)
local_mse[i,j]<-mean((test$mpg-local_pred)^2)
}

#knots up to 30


for (j in 1:30){
knot_number=j
knot_points <- seq(min(test$displacement), max(test$displacement), length.out = knot_number + 2)[2:(knot_number + 1)]
cubic_spline<-lm(data=train,mpg~bs(displacement, knots=knot_points))
cubic_pred<-predict(cubic_spline,newdata=test_displacement)
cubic_mse[i,j]<-mean((test$mpg-cubic_pred)^2)
}

}
```

```{r}
#Local MSE seems to randomly have issues with NA values, so I filled the missing row
i=7
for (j in 10:20){
span_val=0.01*j
local_regression_fit<-loess(mpg~displacement,data=train, span=span_val)
local_pred<-predict(local_regression_fit,newdata=displacement_values)
local_mse[i,j]<-mean((test$mpg-local_pred)^2)
}


```

```{r}
#Here we found the lowest average MSE for each parameter and chose the ideal value from that

which(colMeans(poly_mse)==min(colMeans(poly_mse)))
#So we should use a polynomial of degree 2


#Only use columns 10-20 since that's what we tested
which(colMeans(local_mse)==min(colMeans(local_mse[,10:20])))

#So we should use a span of 0.18

which(colMeans(cubic_mse)==min(colMeans(cubic_mse)))

#So we should use 8 knots
```

3.  Calculating MSEs with 8 fold cross verification

    ```{r}
    set.seed(1002)
    k=8
    n=392
    width=n/k
    test_indexes<-sample(1:392,replace=FALSE,n)

    #initialize MSEs
    poly_MSE=matrix(ncol=k,nrow=1,0)
    step_MSE=matrix(ncol=k,nrow=1,0)
    cubic_MSE=matrix(ncol=k,nrow=1,0)
    natural_MSE=matrix(ncol=k,nrow=1,0)

    local_MSE=matrix(ncol=k,nrow=1,0)




    for (i in 1:k){

    #initialize folds
    test<-data.frame("mpg"=df[(test_indexes[as.integer(width*(i-1) ):as.integer(width*i)]),1],"displacement"=df[test_indexes[as.integer(width*(i-1) ):as.integer(width*i)],3])
    test_displacement<-data.frame("displacement"=test$displacement)
    train_index<-setdiff(test_indexes,test_indexes[as.integer(width*(i-1) ):as.integer(width*i)])
    train<-data.frame("mpg"=df[train_index,1],"displacement"=df[train_index,3])


    #Fits
    poly_degree=2

    polyfit<- lm(data=df, mpg~ poly(displacement,poly_degree))

    poly_pred<-predict(polyfit,newdata=test_displacement)


    ##Step Function Regression
    ##cuts=4


    ##stepfunctionfit<-lm(data=train, mpg~cut(displacement,cuts))


    ##step_pred<-predict(stepfunctionfit,newdata=test_displacement)


    ##Cubic Spline
    library(splines)
    knot_number=8
    knot_points=cut(train$displacement,knot_number)
    cubic_spline<-lm(data=train,mpg~bs(displacement, knots=knot_points))
    cubic_pred<-predict(cubic_spline,newdata=test_displacement)

    ##Natural Spline
    degrees_of_freedom=5
    natural_spline<-lm(data=train,mpg~ns(displacement, df=degrees_of_freedom,))
    natural_pred<-predict(natural_spline,newdata=test_displacement)

    #No need for smoothing spline, as we already found the MSE


    ##Local Regression
    span_val=0.18
    local_regression_fit<-loess(mpg~displacement,data=train, span=span_val)
    local_pred<-predict(local_regression_fit,newdata=test_displacement)





    ##MSE calculations
    poly_MSE[i]<-mean((test$mpg-poly_pred)^2)

    #Had trouble with step MSE, so I just used the total MSE
    step_MSE[i]<-mean((df$mpg-step_pred)^2)

    cubic_MSE[i]<-mean((test$mpg-cubic_pred)^2)
    natural_MSE[i]<-mean((test$mpg-natural_pred)^2)
    local_MSE[i]<-mean((test$mpg-local_pred)^2)
    }


    #error with i =2 in local_mse and I had trouble fixing it
    #replaced with average of the other 7 values
    local_MSE[2]<-(1/7)*(local_MSE[1]+local_MSE[6]+local_MSE[3]+local_MSE[4]+local_MSE[5]+local_MSE[7]+local_MSE[8])


    #already min with cv function
    smooth_MSE<-mean((no_duplicated_df$mpg-smooth_pred$y)^2)


    #average MSEs
    mean(poly_MSE)
    mean(step_MSE)
    mean(cubic_MSE)
    mean(natural_MSE)
    print(smooth_MSE)
    mean(local_MSE)



    ```

Based of of these MSEs, I chose local regression as the best model in this case.

4.  My important value was the median of all displacement values to see how well the model predicts median mpg in cars. This can show how well the model is measuring a different description of spread that is not the mean

    ```{r}
    x0=median(df$displacement)
    span_val=0.18
    local_regression_fit<-loess(mpg~displacement,data=df, span=span_val)
    x0_pred<-predict(local_regression_fit,newdata=x0)

    print(x0_pred)


    ```

5.  This model is telling us that if we model mpg only on displacement, then the median displacement would imply that the median mpg is about 25.21. This is not actually true as the median value is about 3mpg lower. This is telling us that displacement is likely not the only relevant predictor to mpg. See below:

    ```{r}
    median(df$mpg)
    ```

6.  Ethical Implications:

    Some of the ethical implications of this work include using this information for car manufacturing companies to maximize mpg. This might lead to lower carbon emissions, but also with this information car manufacturing companies could seek to lower mpg with "bad" displacements in order to help oil companies maximize profits. This data could be used in many other ways as well.

7.  Visualizations

    ```{r}
    ##Loading the dataset
    library(ISLR2)
    df <- data.frame(Auto)

    displacement_values<-data.frame("displacement"=df$displacement)


    ##Polynomial Regression

    poly_degree=2

    polyfit<- lm(data=df, mpg~ poly(displacement,poly_degree))

    poly_pred<-predict(polyfit,newdata=displacement_values)




    ##Step Function Regression
    cuts=4
    stepfunctionfit<-lm(data=df, mpg~cut(displacement,cuts))

    step_pred<-predict(stepfunctionfit,newdata=displacement_values)



    ##Cubic Spline
    library(splines)
    knot_number=8
    knot_points=cut(df$displacement,knot_number)
    cubic_spline<-lm(data=df,mpg~bs(displacement, knots=knot_points))
    cubic_pred<-predict(cubic_spline,newdata=displacement_values)

    ##Natural Spline
    degrees_of_freedom=5
    natural_spline<-lm(data=df,mpg~ns(displacement, df=degrees_of_freedom,))
    natural_pred<-predict(natural_spline,newdata=displacement_values)

    ##Smoothing Spline

    duplicates<-duplicated(df$displacement)
    no_duplicated_df<-df[!duplicated(df[c('displacement')]), ]

    s_spline<-smooth.spline(no_duplicated_df$displacement,no_duplicated_df$mpg,cv=TRUE)
    no_dup_dis<-data.frame("displacement"=no_duplicated_df$displacement)
    smooth_pred<-predict(s_spline, newdata=no_dup_dis)

    #CV cross-validated df is
    print(s_spline$df)


    ##Local Regression
    span_val=0.18
    local_regression_fit<-loess(mpg~displacement,data=df, span=span_val)
    local_pred<-predict(local_regression_fit,newdata=displacement_values)

    ##Plot of fits
    library(ggplot2)

    ggplotstuff<-data.frame("mpg"=df$mpg,"displacement"=df$displacement,"poly"=poly_pred,"step"=step_pred,"cubic"=cubic_pred,"natural"=natural_pred,"local"=local_pred)

    ggplot(ggplotstuff,aes(y=mpg,x=displacement))+
      geom_point(color='black')+
      geom_line(aes(y=poly,x=displacement),color='blue')+
      geom_line(aes(y=step,x=displacement),color='red')+
      geom_line(aes(y=cubic,x=displacement),color='cyan')+
      geom_line(aes(y=natural,x=displacement),color='yellow')+
      geom_line(aes(y=local,x=displacement),color='pink')

    #seperate plot for smooth because it has trouble with duplicates

    duplicates<-duplicated(df$displacement)
    no_duplicated_df<-df[!duplicated(df[c('displacement')]), ]
    plot_stuff<-data.frame("mpg"=no_duplicated_df$mpg,"displacement"=no_duplicated_df$displacement,"smooth"=smooth_pred$y)

    ggplot(plot_stuff,aes(y=mpg,x=displacement))+geom_point(color='black')+
             geom_line(aes(y=smooth,x=displacement),color='orange')




    #A plot of just the local regression model:
    ggplot(ggplotstuff,aes(y=mpg,x=displacement))+
      geom_point(color='black')+
      geom_line(aes(y=local,x=displacement),color='pink')
    ```

I had trouble creating the legend on ggplot so I note it here:

blue=polynomial regression model

red=step model

cyan=cubic spline model

yellow=natural spline model

pink=local regression model

orange=smoothing spline model

# Rishi Individual :

#### Part 1: Fitting the six models

```{r}
library(ISLR2)
data("Auto")
poly_model <- lm(mpg ~ poly(acceleration, 2), data = Auto)
summary(poly_model)

library(splines)
step_model <- lm(mpg ~ cut(acceleration, breaks = 4), data = Auto)
summary(step_model)

cubic_model <- lm(mpg ~ ns(acceleration, df = 4), data = Auto)
summary(cubic_model)

natural_model <- lm(mpg ~ ns(acceleration, df = 4), data = Auto)
summary(natural_model)

smoothing_model <- smooth.spline(Auto$acceleration, Auto$mpg)
summary(smoothing_model)

library(ggplot2)
local_model <- loess(mpg ~ acceleration, data = Auto)
summary(local_model)

```

#### Part 2: Using CV to determine optimal tuning

```{r}
library(caret)

train_control <- trainControl(method = "LOOCV")

cv_poly <- train(mpg ~ poly(acceleration, 2), data = Auto, method = "lm", trControl = train_control)
print(cv_poly)

cv_cubic <- train(mpg ~ ns(acceleration, df = 4), data = Auto, method = "lm", trControl = train_control)
print(cv_cubic)

cv_step <- train(mpg ~ cut(acceleration, breaks = 4), data = Auto, method = "lm", trControl = train_control)
print(cv_step)


```
# Will Individual

```{r}
data(Auto)
```


```{r}
library(ISLR2) 
library(gam) 
library(splines)
library(locfit) 
library(boot) 
library(ggplot2)
poly <- lm(mpg ~ poly(weight, 4), data = Auto)
bins <- cut(Auto$weight, breaks = 4)
step <- lm(mpg ~ bins, data = Auto)
cubic <- lm(mpg ~ bs(weight, degree = 3), data = Auto)
natural <- lm(mpg ~ ns(weight, df = 4), data = Auto)
smooth <- smooth.spline(Auto$mpg, Auto$weight)
local <- loess(mpg ~ weight, data = Auto, span = 0.75)
cv <- function(model_formula, data, K = 8) {
  n <- nrow(data) 
  folds <- sample(1:K, n, replace = TRUE) 
  mse <- rep(0, K)
  for (k in 1:K) {
    test_indices <- which(folds == k) 
    train_data <- data[-test_indices, ] 
    test_data <- data[test_indices, ]
    fitted_model <- lm(model_formula, data = train_data)
    predictions <- predict(fitted_model, newdata = test_data)
    actual_values <- test_data[, all.vars(model_formula)[1]]  
    mse[k] <- mean((predictions - actual_values)^2, na.rm = TRUE)
  }
  return(mean(mse))
}
```


```{r}
Auto$bins <- cut(Auto$weight, breaks = 4)
poly_formula <- mpg ~ poly(weight, 4)
step_formula <- mpg ~ bins  # Use the predefined bins
cubic_formula <- mpg ~ bs(weight, degree = 3)
natural_formula <- mpg ~ ns(weight, df = 4)
local_formula <- mpg ~ weight  
poly_mse <- cv(poly_formula, Auto, K = 8)
step_mse <- cv(step_formula, Auto, K = 8)
cubic_mse <- cv(cubic_formula, Auto, K = 8)
natural_mse <- cv(natural_formula, Auto, K = 8)
print(paste("Polynomial Model MSE:", round(poly_mse, 4)))
print(paste("Step Function Model MSE:", round(step_mse, 4)))
print(paste("Cubic Spline Model MSE:", round(cubic_mse, 4)))
print(paste("Natural Spline Model MSE:", round(natural_mse, 4)))
local_predictions <- predict(loess(mpg ~ weight, data = Auto, span = 0.75), newdata = Auto)
local_mse <- mean((local_predictions - Auto$mpg)^2, na.rm = TRUE)
print(paste("Local Regression MSE:", round(local_mse, 4)))
print(paste("Smoothing Spline MSE:", round(smooth_mse, 4)))

```
```{r}
step_knots <- levels(cut(Auto$weight, breaks = 4))  # 4 bins → 3 internal knots
cat("Step Function Knots:", length(step_knots) - 1, "\n") 
cubic_spline_model <- bs(Auto$weight, degree = 3, knots = quantile(Auto$weight, probs = c(0.25, 0.5, 0.75)))
cubic_knots <- attr(cubic_spline_model, "knots")
cat("Cubic Spline Knots:", length(cubic_knots), "\n")
natural_spline_model <- ns(Auto$weight, df = 4)  # df = 4 → 3 internal knots
natural_knots <- attr(natural_spline_model, "knots")  
cat("Natural Spline Knots:", length(natural_knots), "\n")
smooth_spline_model <- smooth.spline(Auto$weight, Auto$mpg)  # Auto-selects knots
smooth_knots <- smooth_spline_model$fit$knot  
cat("Smoothing Spline Knots:", length(smooth_knots), "\n")

```
```{r}
median_weight <- median(Auto$weight, na.rm = TRUE)
predicted_mpg <- predict(cubic, newdata = data.frame(weight = median_weight))
print(predicted_mpg)

```


When comparing the MSE for all six models, I found that the Local Regression slightly outperformed the others in terms of prediction accuracy. My key metric was the median weight of all vehicles to determine how well the model predicts mpg at a typical vehicle weight. This helps evaluate the model's ability to capture real-world fuel efficiency trends without being skewed by extreme values at the high or low ends of the weight spectrum. According to this model, for a vehicle with the median weight, the expected mpg is approximately 23.75. This suggests that while weight is a significant factor in fuel efficiency, other variables  likely play a role as well. The ethical implications of this model include the risk of oversimplifying fuel efficiency predictions. An ethical concern would be that if consumers rely solely on weight to estimate mpg, they might overlook other important factors such as vehicle design, maintenance, and driving behavior. This could lead to misleading conclusions when choosing a car based only on weight, potentially affecting purchasing decisions and sustainability efforts.

#### Part 3: Comparing CV RMSE

```{r}
cv_poly$results$RMSE
cv_cubic$results$RMSE
cv_step$results$RMSE
```

#### Part 4: Important/Significant value of X

```{r}
best_model <- cubic_model
prediction <- predict(best_model, newdata = data.frame(acceleration = 15.5))
prediction

```

I chose acceleration = 15.5 because I wanted to check the average acceleration which I found to be 15.54133 so I just left it at 15.5.

#### Part 5: What the model means

The model predicts that a car with an acceleration of 15.5 will have about 25.48 mpg. This means that, on average, cars with this level of acceleration tend to have moderate fuel efficiency.

#### Part 6: Ethical Implications

One ethical implication could be the potential for biased predictions if the dataset doesn't represent a diverse range of cars. For example, if the data only has cars from a specific region or the type of car then the model might not be able to predict mpg accurately

```{r}
library(ISLR)
library(gam)
library(splines)
library(locfit)
library(boot)
library(ggplot2)

data(Auto)
Auto <- Auto[!duplicated(Auto), ]

# Polynomial Model
poly <- lm(mpg ~ poly(horsepower, 4), data = Auto)

# Step Function Model
bins <- cut(Auto$horsepower, breaks = 4)
step <- lm(mpg ~ bins, data = Auto)

# Cubic Spline Model
cubic <- lm(mpg ~ bs(horsepower, degree = 3), data = Auto)

# Natural Spline Model
natural <- lm(mpg ~ ns(horsepower, df = 4), data = Auto)

# Smoothing Spline
smooth <- smooth.spline(Auto$mpg, Auto$horsepower)

# Local with span parameter
local <- loess(mpg ~ horsepower, data = Auto, span = 0.75)

# Define cross-validation function for models
cv_model <- function(model, data, K = 8) {
  n <- nrow(data)
  folds <- sample(1:K, n, replace = TRUE)
  mse <- rep(0, K)
  
  for (k in 1:K) {
    test_indices <- which(folds == k)
    train_data <- data[-test_indices, ]
    test_data <- data[test_indices, ]
    
    # Fit model on training data
    if (inherits(model, "loess")) {
      fit <- loess(mpg ~ horsepower, data = train_data, span = 0.75)
      pred <- predict(fit, newdata = test_data)
    } else {
      fit <- lm(mpg ~ horsepower, data = train_data)
      pred <- predict(fit, newdata = test_data)
    }
    
    # Calculate MSE for the fold
    mse[k] <- mean((pred - test_data$mpg)^2)
  }
  return(mean(mse))
}

cv_poly_mse <- cv_model(poly, Auto)
cv_step_mse <- cv_model(step, Auto)
cv_cubic_mse <- cv_model(cubic, Auto)
cv_natural_mse <- cv_model(natural, Auto)
cv_smooth_mse <- cv_model(smooth, Auto)
cv_local_mse <- cv_model(local, Auto)

print(paste("Polynomial model MSE:", cv_poly_mse))
print(paste("Step function model MSE:", cv_step_mse))
print(paste("Cubic spline model MSE:", cv_cubic_mse))
print(paste("Natural spline model MSE:", cv_natural_mse))
print(paste("Smoothing spline model MSE:", cv_smooth_mse))
print(paste("Local regression model MSE:", cv_local_mse))

# Using Step Function
best_model <- step  
# Choose the significant value
x0 <- median(Auto$horsepower)
bins_x0 <- cut(x0, breaks = 4, include.lowest = TRUE, labels = levels(bins))  
predicted_mpg <- predict(best_model, newdata = data.frame(bins = bins_x0))

print(predicted_mpg)
```

```{r}
library(ISLR)
library(gam)
library(splines)
library(locfit)
library(boot)
library(ggplot2)

data(Auto)
Auto <- Auto[!duplicated(Auto), ]

# Cross-validation function for different model types
cv_model <- function(model_type, data, K = 8, degree = NULL, df = NULL, bins = NULL) {
  set.seed(123)  # Ensures reproducibility
  n <- nrow(data)
  folds <- sample(1:K, n, replace = TRUE)
  mse <- rep(0, K)
  
  for (k in 1:K) {
    test_indices <- which(folds == k)
    train_data <- data[-test_indices, ]
    test_data <- data[test_indices, ]
    
    # Fit the model based on type
    if (model_type == "poly") {
      fit <- lm(mpg ~ poly(horsepower, degree), data = train_data)
      pred <- predict(fit, newdata = test_data)
    } else if (model_type == "step") {
      train_data$bins <- cut(train_data$horsepower, breaks = bins)
      test_data$bins <- cut(test_data$horsepower, breaks = bins, labels = levels(train_data$bins))
      fit <- lm(mpg ~ bins, data = train_data)
      pred <- predict(fit, newdata = test_data)
    } else if (model_type == "cubic") {
      fit <- lm(mpg ~ bs(horsepower, degree = 3), data = train_data)
      pred <- predict(fit, newdata = test_data)
    } else if (model_type == "natural") {
      fit <- lm(mpg ~ ns(horsepower, df = df), data = train_data)
      pred <- predict(fit, newdata = test_data)
    } else if (model_type == "smooth") {
      fit <- smooth.spline(train_data$horsepower, train_data$mpg)
      pred <- predict(fit, test_data$horsepower)$y
    } else if (model_type == "loess") {
      fit <- loess(mpg ~ horsepower, data = train_data, span = 0.75)
      pred <- predict(fit, newdata = test_data)
    }
    
    # Compute MSE
    mse[k] <- mean((pred - test_data$mpg)^2, na.rm = TRUE)
  }
  
  return(mean(mse, na.rm = TRUE))
}

# Run cross-validation for each model
cv_poly_mse <- cv_model("poly", Auto, degree = 4)
cv_step_mse <- cv_model("step", Auto, bins = 4)
cv_cubic_mse <- cv_model("cubic", Auto)
cv_natural_mse <- cv_model("natural", Auto, df = 4)
cv_smooth_mse <- cv_model("smooth", Auto)
cv_local_mse <- cv_model("loess", Auto)

print(paste("Polynomial model MSE:", cv_poly_mse))
print(paste("Step function model MSE:", cv_step_mse))
print(paste("Cubic spline model MSE:", cv_cubic_mse))
print(paste("Natural spline model MSE:", cv_natural_mse))
print(paste("Smoothing spline model MSE:", cv_smooth_mse))
print(paste("Local regression model MSE:", cv_local_mse))

# Choosing best model (lowest MSE)
mse_values <- c(cv_poly_mse, cv_step_mse, cv_cubic_mse, cv_natural_mse, cv_smooth_mse, cv_local_mse)
model_names <- c("Polynomial", "Step Function", "Cubic Spline", "Natural Spline", "Smoothing Spline", "Local Regression")

best_model_name <- model_names[which.min(mse_values)]
best_model <- which.min(mse_values)

print(paste("Best model:", best_model_name, "with MSE =", min(mse_values)))

# Predict using Step Function (if chosen)
if (best_model_name == "Step Function") {
  x0 <- median(Auto$horsepower)
  bins_x0 <- cut(x0, breaks = 4, include.lowest = TRUE)
  predicted_mpg <- predict(lm(mpg ~ bins, data = Auto), newdata = data.frame(bins = bins_x0))
  print(predicted_mpg)
}


```
3. When comparing the MSE for all 6 models I found that the Natural Spline model outperformed the other models slightly.

4. My important value was the median of all horsepower values to see how well the model predicts mpg at a typical horsepower level. This can show how well the model captures the performance of the average car, rather than being influenced by extreme values at the high or low ends of horsepower.

5. This model is telling us that if we model mpg based on horsepower, the median horsepower would imply that the median mpg is about 23.79. This suggests that other factors likely influence fuel efficiency.

6. The ethical implications of this model would be if we predicted mpg solely based on horsepower, it would overlook factors such as vehicle age, maintenance, and driving behavior, which are also important in determining fuel efficiency. This could lead to inaccurate conclusions that fail to consider the full context of car performance. This could lead to consumers being mislead when trying to find the best car with affordable mpg.


#### What teams need to do

1.  Create a GAM based on the work of your individual team members.
2.  Visualize the GAM (R has some good built-in plotting functions, such as plot.gam()).
3.  Choose a value of X that is important or interesting (explain why) and use that point to make a prediction for Y. Interpret this prediction.
4.  How does the GAM compare with a linear method (e.g., lasso, ridge, PCR, etc.)?

#### Individual contributions to team GAM

Each individual must comment on their contributions to the team GAM. For example, write something like: ‘I told person X that my results showed that the natural spline with 4 knots was the best model for variable x1. Then I created a visualization to help interpret the GAM.’ Or, ‘I used the GAM to make a prediction for the point x0.’ Or, ‘I didn’t actually do anything for the team section.’ Only individuals who contribute to the team section will get points for the team section.

#### **Some intended outcomes from this assignment:**

-   You will individually get practice fitting a nonlinear regression models: polynomial regression, step function regression, cubic spline, natural spline, smoothing spline, and local regression
-   You will practice using CV to select the optimal tuning parameters of your models
-   You will use CV to compare the performance of these models
-   You will make predictions based on your models
-   You will practice fitting and interpreting a GAM
-   You will gain experience working on a data science "project" as a team
