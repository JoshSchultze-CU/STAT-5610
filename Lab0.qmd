---
title: "LAB0"
author: "Mountain Dewds"
format: pdf
editor: visual
---

## Individual Assigments

Josh:

![](images/IMG_4202.jpg)

This is a photo of me cross country skiing for the first time over winter break. I went with my fiance and her mother in Oregon. It was so much harder than downhill skiing in my opinion!\

I want to know what percent of a musician's success is from time practicing, connections with people in industry, and purely luck. I'm not how someone could measure success though, maybe through album sales and net worth?

I would be excited to finally have a full time job and be in industry. Right now I want to be involved with modeling or risk assessment. Ideally I would be at a consulting firm.\

My greatest career accomplishment would be running my own statistical consulting firm. I want to be my own boss, but stay working in industry.\

I am hoping to learn how to apply my knowledge to real life problems. I hope to use QQQ and learn how to best interpet statistics to give advice for future development. I also want to learn the most effective ways to work within a team.\

I have been playing guitar for about 2 years. I used to play the drums in high school, but they took up too much space in my apartment during undergraduate, so I took up guitar. I was in a band in my last year of undergraduate, and I'm hoping to start another soon in the Denver/Boulder area!

## About Our Team

![](images/IMG_5482.jpg)

**Team Name:** Mountain Dewds!

**Main Goal for this Semester:**
We want to continue doing well on the trat exams. We also want to learn how to apply the learning methods in this class.

## Applied Portion

## Individual

**Josh:**

Below is the code given in the lab:

```{r}
library(class)
library(tidyverse)
```

```{r}
#Generative model
set.seed(127) #setting a random seed so that we can reproduce everything exactly if we want t
generate_y <- function(x1,x2) { #two input parameters to generate the output y
logit <- x1 -2*x2 -2*x1^2 + x2^2 + 3*x1*x2 +4*x1*x2^2 -3*x1^2*x2
p <- exp(logit)/(1+exp(logit)) #apply the inverse logit function
y <- rbinom(1,1,p) #y becomes a 0 (with prob 1-p) or a 1 with probability p
}
```

```{r}
# Generate a dataset with 100 points
set.seed(127)
n = 100
X1 <- runif(n,0,1)
X2 <- runif(n,0,1)
#I'm going to use a for loop to generate 100 y's
Y <- rep(0,n) #initializing my Y to be a vector of 0's
for (i in 1:n) {
Y[i] <- generate_y(X1[i],X2[i])
}
sum(Y) #How many 0's and 1's were predicted? In this training set, 37% were 1's. However, bet
training <- cbind(X1,X2,Y) #combining all of my variables into a training dataset
ggplot(data=training, aes(x=X1, y=X2, color=Y)) +
geom_point()
```

```{r}
# Create the training dataset as above using seed=127
# Create a testing dataset using seed=128
set.seed(128)
n = 100
X1 <- runif(n,0,1)
X2 <- runif(n,0,1)
#I'm going to use a for loop to generate 100 y's
Y <- rep(0,n) #initializing my Y to be a vector of 0's
for (i in 1:n) {
Y[i] <- generate_y(X1[i],X2[i])
}
sum(Y) #53 1's, which is much closer to the 51.5% true rate
testing <- cbind(X1,X2,Y)
#Let's plot the test set. Does it look like the training set? Yeah, looks similar.
ggplot(data=testing, aes(x=X1, y=X2, color=Y)) +
geom_point()
```

1\. Given the training set (seed=127) and the testing set (seed=128), fit KNN on two dif-\
ferent values of k.

First I tried with k=3 and then k=50

```{r}
knn3predictions <- knn(train=training[,1:2], cl=training[,3], test = testing[,1:2], k = 3)

knn3predictions <- data.frame(testing,knn3predictions)


knn50predictions <- knn(train=training[,1:2], cl=training[,3], test = testing[,1:2], k = 50)

knn50predictions<- data.frame(testing,knn50predictions)


```

\
2. Calculate the misclassification rate for each k. If you don’t know how to do this, ask a\
teammate or the professor.

I tried to do this directly, I'm not sure if there is a function in R that does this. Below are the misclassification rates for k=3 and k =50 respectively.

```{r}
knn3misclassificationrate=sum(knn3predictions[,3]!=knn3predictions[,4])/length(knn3predictions[,3])
knn3misclassificationrate
knn50misclassificationrate=sum(knn50predictions[,3]!=knn50predictions[,4])/length(knn50predictions[,3])
knn50misclassificationrate
```

3\. If possible, plot the decision boundaries for your k values.

I had trouble doing this, so I did not present it here.

\
4. Summarize the Q1, Q2, and Q3 aspects of this “project.” Use your imagination. Everyone\
should have a different scenario.

A company wants to launch a new hot dog campaign over blu-ray ads in blue-rays and products in the top shelves of stores. The slogan is "hot dogs are the best sandwhich!" They collected data on where they should market this, including respondents height and amount spent on blu-ray dvds. Q1 in this case could be data collected from a survey of individuals who think hot dogs are a sandwich over their amount spent on blu-ray dvds in the past year and height. The X1 column is each observation's amount spent in dollars on blu-ray dvds and X2 is each respondents height. The class, Y, is whether or not the respondent believes a hot dog is a sandwich. The Q2 aspect of this project is using knn to identify decision boundaries on height and amount spent on blu-rays to find any relationship. In Q3, we would conclude that there is likely no relationship between these variables and the class, so this company should not invest differently in blu-ray dvd ads or markets that prioritize tall individuals.

\
5. Think about and discuss with your team some of the bonus questions below.

## Team

Which K value is best from what we tested?

After comparing our individual portions, we decided that a k value of
